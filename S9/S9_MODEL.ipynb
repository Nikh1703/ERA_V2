{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CK7gH5qxus4L"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kDJAQbH4us4N"
      },
      "outputs": [],
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.RandomRotation(15),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values.\n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                                       ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCMydL5pus4O",
        "outputId": "44fc4998-3ab5-45b6-ece2-9e84517b5fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transforms)\n",
        "test = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq9lWK4Rus4O",
        "outputId": "31b7d081-8856-4fd5-e6f1-d76cfe291447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? False\n"
          ]
        }
      ],
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "mGIbylssus4P",
        "outputId": "a1dacf23-1fb1-4228-def2-54ad72fa16b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ship  bird  cat   dog  \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "import torchvision\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "-1oVPfnEus4P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomCNN, self).__init__()\n",
        "\n",
        "        # Convolution Block 1 - Standard Convolution\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1, stride=1, dilation=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2, dilation=1), # Stride 2 here\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )  # Receptive field: 5\n",
        "\n",
        "        # Convolution Block 2 - Standard Convolution\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            #nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=2), # Stride 2 here\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128)\n",
        "        )  # Receptive field: 14\n",
        "\n",
        "        # Convolution Block 3 - Depthwise Separable Convolution with Dilation\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=2, stride=1, groups=128, dilation=2),\n",
        "           # nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1),  # Pointwise\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=2, groups=256), # Stride 2 here\n",
        "           # nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1),  # Pointwise\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )  # Receptive field: 32 (approx, considering dilations)\n",
        "\n",
        "        # Convolution Block 4 - Depthwise Separable Convolution\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1, groups=256),\n",
        "           # nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1),  # Pointwise\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=2, groups=512), # Stride 2 here\n",
        "          #  nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1),  # Pointwise\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(512)\n",
        "        )  # Receptive field: 44 (approx)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Check the model's total parameters to ensure they are under 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jg9Fe4ous4P",
        "outputId": "a65787e8-a413-4323-db8f-b6933bb92051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cpu\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "              ReLU-2           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
            "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
            "              ReLU-5           [-1, 64, 16, 16]               0\n",
            "       BatchNorm2d-6           [-1, 64, 16, 16]             128\n",
            "            Conv2d-7          [-1, 128, 16, 16]          73,856\n",
            "              ReLU-8          [-1, 128, 16, 16]               0\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "           Conv2d-10            [-1, 128, 8, 8]         147,584\n",
            "             ReLU-11            [-1, 128, 8, 8]               0\n",
            "      BatchNorm2d-12            [-1, 128, 8, 8]             256\n",
            "           Conv2d-13            [-1, 128, 8, 8]           1,280\n",
            "           Conv2d-14            [-1, 256, 8, 8]          33,024\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "           Conv2d-17            [-1, 256, 4, 4]           2,560\n",
            "           Conv2d-18            [-1, 256, 4, 4]          65,792\n",
            "             ReLU-19            [-1, 256, 4, 4]               0\n",
            "      BatchNorm2d-20            [-1, 256, 4, 4]             512\n",
            "           Conv2d-21            [-1, 256, 4, 4]           2,560\n",
            "           Conv2d-22            [-1, 512, 4, 4]         131,584\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-24            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-25            [-1, 512, 2, 2]           5,120\n",
            "           Conv2d-26            [-1, 512, 2, 2]         262,656\n",
            "             ReLU-27            [-1, 512, 2, 2]               0\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "AdaptiveAvgPool2d-29            [-1, 512, 1, 1]               0\n",
            "           Linear-30                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 754,314\n",
            "Trainable params: 754,314\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.91\n",
            "Params size (MB): 2.88\n",
            "Estimated Total Size (MB): 5.80\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = CustomCNN(num_classes=10)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VP0IA6FDus4P"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "3Kc2o_AIus4Q",
        "outputId": "b224da85-1245-49cb-b2b5-cdf11a95a46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.4858410358428955 Batch_id=781 Accuracy=41.31: 100%|██████████| 782/782 [04:35<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.3631, Accuracy: 4989/10000 (49.89%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.1486260890960693 Batch_id=781 Accuracy=53.06: 100%|██████████| 782/782 [04:18<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.1428, Accuracy: 5906/10000 (59.06%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9954930543899536 Batch_id=781 Accuracy=57.58: 100%|██████████| 782/782 [04:24<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0109, Accuracy: 6390/10000 (63.90%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.284401774406433 Batch_id=781 Accuracy=60.55: 100%|██████████| 782/782 [04:18<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9767, Accuracy: 6508/10000 (65.08%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8092230558395386 Batch_id=781 Accuracy=62.31: 100%|██████████| 782/782 [04:20<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.9416, Accuracy: 6644/10000 (66.44%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9275938868522644 Batch_id=706 Accuracy=63.88:  90%|█████████ | 707/782 [04:22<00:27,  2.69it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-213e5f6a7fca>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EPOCH:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-1f287ad9bbd8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7e7c2be4de6d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvblock7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvblock8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvblock9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    # scheduler.step()\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzEEHWpuus4Q"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYQ_v4HXus4Q"
      },
      "outputs": [],
      "source": [
        "# we will save the conv layer weights in this list\n",
        "model_weights =[]\n",
        "#we will save the 49 conv layers in this list\n",
        "conv_layers = []\n",
        "# get all the model children as list\n",
        "model_children = list(model.children())\n",
        "#counter to keep count of the conv layers\n",
        "counter = 0\n",
        "#append all the conv layers and their respective wights to the list\n",
        "\n",
        "model_children = model.children()\n",
        "for children in model_children:\n",
        "    if type(children) == nn.Sequential:\n",
        "        for child in children:\n",
        "            if type(child) == nn.Conv2d:\n",
        "                counter += 1\n",
        "                model_weights.append(child.weight)\n",
        "                conv_layers.append(child)\n",
        "\n",
        "print(f\"Total convolution layers: {counter}\")\n",
        "print(\"conv_layers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2g6oQ_lus4Q"
      },
      "outputs": [],
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "imshow(torchvision.utils.make_grid(images[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tvok0nFus4R"
      },
      "outputs": [],
      "source": [
        "image = images[9]\n",
        "imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTkrdgTGus4R"
      },
      "outputs": [],
      "source": [
        "image = image.unsqueeze(0)\n",
        "image = image.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-e2-UxWus4R"
      },
      "outputs": [],
      "source": [
        "outputs = []\n",
        "names = []\n",
        "for layer in conv_layers[0:]:\n",
        "    image = layer(image)\n",
        "    outputs.append(image)\n",
        "    names.append(str(layer))\n",
        "print(len(outputs))\n",
        "#print feature_maps\n",
        "for feature_map in outputs:\n",
        "    print(feature_map.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC_XINoxus4R"
      },
      "outputs": [],
      "source": [
        "processed = []\n",
        "for feature_map in outputs:\n",
        "    feature_map = feature_map.squeeze(0)\n",
        "    gray_scale = torch.sum(feature_map,0)\n",
        "    # gray_scale = feature_map[0]\n",
        "    gray_scale = gray_scale / feature_map.shape[0]\n",
        "    processed.append(gray_scale.data.cpu().numpy())\n",
        "for fm in processed:\n",
        "    print(fm.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxE0L5htus4R"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 10))\n",
        "for i in range(len(processed)):\n",
        "    a = fig.add_subplot(5, 4, i+1)\n",
        "    imgplot = plt.imshow(processed[i])\n",
        "    a.axis(\"off\")\n",
        "    a.set_title(names[i].split('(')[0], fontsize=10)\n",
        "plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzeKlQY3us4R"
      },
      "outputs": [],
      "source": [
        "# visualize the first conv layer filters\n",
        "plt.figure(figsize=(5, 4))\n",
        "first_layer_weights = model_weights[0].cpu()\n",
        "for i, filter in enumerate(first_layer_weights):\n",
        "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
        "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ25pSaaus4R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}